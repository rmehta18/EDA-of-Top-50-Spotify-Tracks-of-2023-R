---
title: "PROJECT1"
author: "Gaurang"
date: "2024-03-15"
output:
  pdf_document: default
  word_document: default
---
##load libraries
```{r,echo=FALSE}
library(tidyverse)
library(ggplot2)
library(dplyr)
library(dplyr)
library(tidyr)
library(caret)
library(stringr)
library(randomForest)
library(e1071)
library(gbm)

```

##read dataset
```{r,echo=FALSE,}
df<- read.csv("top_50_2023.csv", sep=",", header=TRUE)
##head(df)
##view(df)
##glimpse(df)
# Check the column names in your dataset
##colnames(df)

```

##cleaning 
```{r,echo=FALSE,eval=FALSE}

###xxxxxxxxx
#select Variables 

df %>%
  select(artist_name,track_name,popularity) 
##xxxxxxxxxxxx
##filter observations 

df %>%
  select(artist_name,track_name,popularity) 
na.omit()
#conclusion no missing data 
class(df$genres)
levels(df$genres)
df$genres<-as.factor(df$genres)
class(df$genres)
levels(df$genres)

###duck with the data 

class(df$genres)
levels(df$genres)
df <- separate_rows(df, genres, sep = ", ")


genre <- "rap"  # Specify the genre for which you want to list track names
rap_songs <- df[df$genres == "", "track_name"]
print(rap_songs)
df %>%
  select(artist_name,genres) 

# Split genres and create a separate row for each genre while preserving song and artist information
df <- df %>%
  mutate(genres = str_split(genres, ", ")) %>%
  unnest(genres)
df %>%
  select(artist_name,genres) 
##################


```



### work 
```{r,echo=FALSE,eval=FALSE}
class(df$is_explicit)
unique(df$is_explicit)
df$is_explicit<- as.factor(df$is_explicit)
class(df$is_explicit)
levels(df$is_explicit)
df$is_explicit <- factor((df$is_explicit),levels = c("True","False"))
levels(df$is_explicit)
df$genres <- gsub("\\[|'|\\]", "", df$genres)

df %>%
  select(artist_name,track_name,popularity,genres) 
# Arrange the dataframe in descending order based on the 'popularity' column
df <- arrange(df, desc(popularity))

# View the arranged dataframe
print(df)
```


#intro 
##1.What are the most common genres among the top tracks?
```{r,echo=FALSE}
# Analyzing common genres among top tracks

# Assuming your dataset is named 'spotify_top_tracks_2023'

# Check the structure of the dataset
##str(df)
df$genres <- gsub("\\[|'|\\]", "", df$genres)

# Count the occurrences of each genre
genre_counts <- table(unlist(df$genres))

# Sort the genres by frequency
sorted_genres <- sort(genre_counts, decreasing = TRUE)

# Display the top N most common genres
N <- 5  # You can adjust this value as needed
top_genres <- head(sorted_genres, N)

# Create a data frame for plotting
genre_data <- data.frame(genre = names(top_genres), frequency = as.numeric(top_genres))

# Plot using ggplot2
ggplot(genre_data, aes(x = reorder(genre, -frequency), y = frequency)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Top 5 Most Common Genres Among Top Tracks",
       x = "Genre", y = "Frequency") +
  theme(axis.text.x = element_text(angle = 0, hjust = 1))  # Rotate x-axis labels
# Count the occurrences of each genre
genre_counts <- df %>% 
  count(genres) %>%
  arrange(desc(n))  # Arrange in descending order of frequency

# Display the top 10 most common genres
top_genres <- head(genre_counts, 10)
print(top_genres)

```
## 2nd 
##Next, let's examine the correlation between track attributes and popularity.
```{r,echo=FALSE}
# Select relevant columns for correlation analysis
selected_cols <- c("danceability", "valence", "energy", "loudness", 
                   "acousticness", "instrumentalness", "liveness", 
                   "speechiness", "tempo", "duration_ms", "time_signature", 
                   "popularity")

# Subset the dataset with selected columns
df_subset <- df %>% 
  select(all_of(selected_cols))

# Compute correlation matrix
correlation_matrix <- cor(df_subset)
# Print correlation matrix
print(correlation_matrix)
# Convert correlation matrix to data frame
correlation_df <- as.data.frame(correlation_matrix)

# Add row names as a column
correlation_df$variable <- rownames(correlation_df)

# Convert correlation matrix to long format
correlation_long <- tidyr::pivot_longer(correlation_df, -variable, names_to = "variable2", values_to = "correlation")

# Plot correlation heatmap
ggplot(correlation_long, aes(variable, variable2, fill = correlation)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", 
                       midpoint = 0, limits = c(-1,1), name = "Correlation") +
  theme_minimal() +
  labs(title = "Correlation Heatmap of Track Attributes and Popularity",
       x = "Track Attributes", y = "Track Attributes") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

#3 
##Predicting Track Popularity
Lastly, we'll attempt to predict track popularity based on its features.

```{r,echo=FALSE}
# Load required libraries
library(caret)  # For training models
library(randomForest)  # For Random Forest model (you can use other models as well)
library(e1071)  # For SVM model (Support Vector Machine)
library(gbm)  # For Gradient Boosting Machine model

# Define predictors and response variable
predictors <- c("danceability", "valence", "energy", "loudness", 
                "acousticness", "instrumentalness", "liveness", 
                "speechiness", "tempo", "duration_ms", "time_signature")
response_var <- "popularity"

# Check if "popularity" is continuous or categorical
if (is.numeric(df[[response_var]]) && length(unique(df[[response_var]])) > 5) {
  # Continuous variable (Regression)
  
  # Convert "popularity" to numeric
  df[[response_var]] <- as.numeric(df[[response_var]])
  
  # Create data partition indices
  set.seed(123)  # For reproducibility
  train_index <- createDataPartition(df[[response_var]], p = 0.8, list = FALSE)
  
  # Subset the dataset into training and testing sets
  train_data <- df[train_index, ]
  test_data <- df[-train_index, ]
  
  # Train Random Forest model for regression
  rf_model <- randomForest(train_data[, predictors], train_data[[response_var]], 
                           ntree = 100, importance = TRUE)
  
  # Make predictions on test data
  rf_predictions <- predict(rf_model, test_data[, predictors])
  
  # Evaluate model performance (e.g., RMSE)
  rmse <- sqrt(mean((test_data[[response_var]] - rf_predictions)^2))
  print(paste("Random Forest RMSE:", rmse))
  
  # Show feature importance
  print("Feature Importance:")
  print(importance(rf_model))
  
} else {
  # Categorical variable (Classification)
  
  # Convert "popularity" to factor
  df[[response_var]] <- as.factor(df[[response_var]])
  
  # Create data partition indices
  set.seed(123)  # For reproducibility
  train_index <- createDataPartition(df[[response_var]], p = 0.8, list = FALSE)
  
  # Subset the dataset into training and testing sets
  train_data <- df[train_index, ]
  test_data <- df[-train_index, ]
  
  # Train Random Forest model for classification
  rf_model <- randomForest(train_data[, predictors], train_data[[response_var]], 
                           ntree = 100, importance = TRUE)
  
  # Make predictions on test data
  rf_predictions <- predict(rf_model, test_data[, predictors])
  
  # Evaluate model performance (e.g., accuracy)
  accuracy <- mean(rf_predictions == test_data[[response_var]])
  print(paste("Random Forest Accuracy:", accuracy))
  
  # Show feature importance
  print("Feature Importance:")
  print(importance(rf_model))
}


```

